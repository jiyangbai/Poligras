# Poligras


An implementation of the "POLIGRAS: Policy-based Graph Summarization".



<!-- A reference Tensorflow implementation is accessible [[here]](https://github.com/yunshengb/SimGNN) and another implementation is [[here]](https://github.com/NightlyJourney/SimGNN). -->

<!-- ### Requirements
The codebase is implemented in Python 3.5.2. package versions used for development are just below.
```
networkx          2.4
tqdm              4.28.1
numpy             1.15.4
pandas            0.23.4
texttable         1.5.0
scipy             1.1.0
argparse          1.1.0
torch             1.1.0
torch-scatter     1.4.0
torch-sparse      0.4.3
torch-cluster     1.4.5
torch-geometric   1.3.2
torchvision       0.3.0
scikit-learn      0.20.0
``` -->
## Datasets


<!--<p align="justify">-->
### *All datasets can be accessed <a href="https://drive.google.com/drive/folders/1v0CGwxQq2sgmraaWWD9nF9OFgwdb44Nv?usp=sharing" target="_blank">[here]</a> (because of the size limitation in Github (<= 25MB), we cannot directly upload some datasets onto Github website)*. 

We have uploaded the astro-ph and cnr-200 (in .zip file) into the `./dataset/`. Before running code on a specific dataset, please make sure to create a file directory with the same name as the dataset at first, then download and unzip dataset files from the given link and put them into the created file directory. 

For example, if running on the in-2004 dataset, users can execute the following steps:

1. Create directory <code>./dataset/in-2004/</code>.
```
mkdir ./dataset/in-2004/
```

2. Download and unzip the in-2004 dataset files, which include the <code>in-2004_graph</code> file that contains the graph structure and the <code>in-2004_feat</code> file that contains node features
```
unzip in-2004_graph.zip
unzip in-2004_feat.zip
```
, then move <code>in-2004_graph</code> file and <code>in-2004_feat</code> file into <code>./dataset/in-2004/</code>.
```
mv in-2004_graph in-2004_feat ./dataset/in-2004/
```

In detail, the <code>in-2004_graph</code> file includes the graph structure in the <code>Networkx</code> graph format, and it can be generated from other graph format (e.g., edge list) by the provided <code>networkx_graph_generation.py</code> file. The <code>in-2004_feat</code> file includes the node feature matrix with row size as the node number and column size as the feature dimension, and it can be generated by the provided <code>node_feature_generation.py</code> file.


<!--first create directory <code>./dataset/in-2004/</code>, then download and unzip the in-2004 dataset (including graph file and node features file) into the directory (i.e., having <code>./dataset/in-2004/in-2004</code> and <code>./dataset/in-2004/in-2004_feat</code>).-->

<!-- Every JSON file has the following key-value structure:

```
#### Model options
```
  --filters-1             INT         Number of filter in 1st GCN layer.       Default is 128.
  --filters-2             INT         Number of filter in 2nd GCN layer.       Default is 64. 
  --filters-3             INT         Number of filter in 3rd GCN layer.       Default is 32.
  --tensor-neurons        INT         Neurons in tensor network layer.         Default is 16.
  --bottle-neck-neurons   INT         Bottle neck layer neurons.               Default is 16.
  --bins                  INT         Number of histogram bins.                Default is 16.
  --batch-size            INT         Number of pairs processed per batch.     Default is 128. 
  --epochs                INT         Number of SimGNN training epochs.        Default is 5.
  --dropout               FLOAT       Dropout rate.                            Default is 0.5.
  --learning-rate         FLOAT       Learning rate.                           Default is 0.001.
  --weight-decay          FLOAT       Weight decay.                            Default is 10^-5.
  --histogram             BOOL        Include histogram features.              Default is False.
``` -->

## Dependencies

<!--<p align="justify">-->
 Install the following tools and packages:
<ul dir="auto">
<li>
    <code>python3</code>
    : Assume 
    <code>python3</code>
     by default (use 
    <code>pip3</code>
     to install packages).
</li>
<li>
    <code>numpy</code>
</li>
<li>
    <code>torch</code>
</li>
<li>
    <code>random</code>
</li>
 <li>
    <code>networkx</code>
</li>
<li>
    <code>copy</code>
</li>
<li>
    <code>argparse</code>
</li>
 <li>
    <code>pickle</code>
</li>
 <li>
    <code>glob</code>
 </li>
</ul>

Users can also run the provided <code>installer.txt</code> to install all the above packages.
```
pip3 install -r installer.txt
```


## To run the code


The following commands train and execute the Poligras model on a specific dataset.
```
python3 src/run.py --dataset dataset_name
```

Users can also set up more model options by:   
<ul dir="auto">
<li><code>--dataset</code> : dataset to run;</li>
<li><code>--counts</code>  : number of graph summarization iterations;</li>
<li><code>--lr</code>      : learning rate;</li>
</ul>
For example, if users want to run Poligras on the astro-ph dataset for 100 iterations with the learning rate as 0.001, users can use the following command:

```
python3 src/run.py --dataset astro-ph --counts 100 --lr 0.001
```

After the running, the total summarization rewards will be printed in the following example format:
```
#super edge: ####
corretion set size: ####

-------SuperNode encoding ended, total reward is ####---------.
```
Apart from the graph summarization rewards, users can also see the final graph summary superedges number and correction set size.



## Code structures

The <code>run.py</code> is to set up all hyperparameters and import the Poligras model implemented in <code>model.py</code>.

The <code>model.py</code> includes the Poligras model details.

The <code>node_feature_generation.py</code> is to generate node features for the given graph.

The <code>networkx_graph_generation.py</code> is to
 











<!-- Training a SimGNN model for a 100 epochs with a batch size of 512.
```
python src/main.py --epochs 100 --batch-size 512
```
Training a SimGNN with histogram features.
```
python src/main.py --histogram
```
Training a SimGNN with histogram features and a large bin number.
```
python src/main.py --histogram --bins 32
```
Increasing the learning rate and the dropout.
```
python src/main.py --learning-rate 0.01 --dropout 0.9
``` -->
